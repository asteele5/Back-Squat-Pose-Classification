# Project Summary

Given a video of a person performing a back squat from a side or front view, this model extracts the coordinates of key pose landmarks from each frame of the video into JSON files using MediaPipe Pose's human pose estimation. These coordinates are then used by the KNN classification algorithm to classify each frame in the video as having good or bad form with 89% accuracy. A percent score based on the number of frames in the video classified as having good form compared to the total frames in the video is then output. The videos used to train the model are not included in the repo due to the large file size. This project won 2nd place at the regional science fair in Loudoun County under the Robotics and Intelligent Machines Category.
